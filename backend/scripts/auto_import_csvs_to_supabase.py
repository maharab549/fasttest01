"""Automate importing exported CSVs into Supabase Postgres.

Prerequisites:
  - SUPABASE_DATABASE_URL env var (service role / full access connection string)
  - CSV files generated by export_sqlite_to_csv.py in ../migration_exports

Usage:
  cd backend
  python scripts/auto_import_csvs_to_supabase.py

Options:
  --force       Import even if table already has rows
  --truncate    Truncate table before import (implies --force)
  --dry-run     Show planned actions only

The script preserves import order respecting foreign keys.
"""
from __future__ import annotations
import os
import sys
import argparse
from pathlib import Path
import psycopg2
import psycopg2.extras

BASE_DIR = Path(__file__).resolve().parent.parent
if str(BASE_DIR) not in sys.path:
    sys.path.insert(0, str(BASE_DIR))

# Import model metadata to get accurate table names and ordering
from app.models import (
    User, Seller, Category, Product, ProductVariant, ProductImage, Order, OrderItem,
    Return, ReturnItem, CartItem, Review, Notification, Message, Favorite,
    SMSMessage, RewardTier, LoyaltyAccount, PointsTransaction, Redemption,
    WithdrawalRequest
)

EXPORT_DIR = BASE_DIR / 'migration_exports'

MODEL_ORDER = [
    User,
    Seller,
    Category,
    Product,
    ProductImage,
    ProductVariant,
    Order,
    OrderItem,
    Return,
    ReturnItem,
    CartItem,
    Review,
    Notification,
    Message,
    Favorite,
    SMSMessage,
    RewardTier,
    LoyaltyAccount,
    PointsTransaction,
    Redemption,
    WithdrawalRequest,
]


def parse_args():
    p = argparse.ArgumentParser(description='Bulk import CSVs into Supabase Postgres using COPY.')
    p.add_argument('--force', action='store_true', help='Import even if table already has rows.')
    p.add_argument('--truncate', action='store_true', help='Truncate tables before import (implies --force).')
    p.add_argument('--dry-run', action='store_true', help='Only show what would be done.')
    return p.parse_args()


def connect(database_url: str):
    conn = psycopg2.connect(database_url)
    conn.autocommit = False
    return conn


def table_row_count(cur, table: str) -> int:
    cur.execute(f'SELECT COUNT(*) FROM "{table}"')
    return cur.fetchone()[0]


def truncate_table(cur, table: str):
    cur.execute(f'TRUNCATE TABLE "{table}" RESTART IDENTITY CASCADE')


def copy_csv(cur, table: str, csv_path: Path):
    # Use COPY ... FROM STDIN WITH CSV HEADER
    with csv_path.open('r', encoding='utf-8') as f:
        cur.copy_expert(f'COPY "{table}" FROM STDIN WITH CSV HEADER', f)


def main():
    args = parse_args()
    if args.truncate:
        args.force = True

    db_url = os.environ.get('SUPABASE_DATABASE_URL')
    if not db_url:
        print('ERROR: SUPABASE_DATABASE_URL not set.')
        sys.exit(1)

    if not EXPORT_DIR.exists():
        print(f'ERROR: Export dir {EXPORT_DIR} not found. Run export script first.')
        sys.exit(1)

    csv_map = {p.stem: p for p in EXPORT_DIR.glob('*.csv')}
    if not csv_map:
        print('No CSV files found.')
        return

    # Build ordered pairs of (csv_stem, table_name)
    ordered_pairs = []
    missing_csv = []
    for model in MODEL_ORDER:
        stem = model.__name__
        table = model.__tablename__
        path = csv_map.get(stem)
        if path is None:
            missing_csv.append(stem)
        ordered_pairs.append((stem, table, path))
    if missing_csv:
        print('WARNING: Missing CSVs for:', ', '.join(missing_csv))

    print('Connecting to Postgres...')
    try:
        conn = connect(db_url)
    except Exception as e:
        print(f'Connection failed: {e}')
        sys.exit(1)

    cur = conn.cursor()

    try:
        for stem, table, path in ordered_pairs:
            if path is None:
                print(f'[SKIP] {table} ({stem}.csv): no CSV found.')
                continue
            existing = table_row_count(cur, table)
            print(f'[INFO] {table}: existing rows={existing}')
            if existing > 0 and not args.force:
                print(f'[SKIP] {table}: has data (use --force to import).')
                continue
            if args.truncate and existing > 0:
                if args.dry_run:
                    print(f'[DRY] Would truncate {table}')
                else:
                    print(f'[DO ] Truncating {table}...')
                    truncate_table(cur, table)
            if args.dry_run:
                print(f'[DRY] Would COPY from {path.name} into {table}')
                continue
            print(f'[DO ] Importing {path.name} -> {table}')
            copy_csv(cur, table, path)
            conn.commit()
            post_count = table_row_count(cur, table)
            print(f'[OK ] {table}: now {post_count} rows')
        if args.dry_run:
            print('Dry run complete. No changes committed.')
    except Exception as e:
        conn.rollback()
        print(f'ERROR during import: {e}')
        sys.exit(1)
    finally:
        cur.close()
        conn.close()


if __name__ == '__main__':
    main()
